{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 19027,
     "status": "ok",
     "timestamp": 1606727581094,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "SkaBphd5jIlX"
   },
   "outputs": [],
   "source": [
    "### -------- Load libraries ------- ###\n",
    "\n",
    "# Load Huggingface transformers\n",
    "from transformers import TFBertModel, BertConfig, BertTokenizerFast\n",
    "\n",
    "# Then what you need from tensorflow.keras\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# And pandas for data import + sklearn because you allways need sklearn\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import itertools\n",
    "import io\n",
    "import os\n",
    "import yaml\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19015,
     "status": "ok",
     "timestamp": 1606727581096,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "qfS1HOOi8seS",
    "outputId": "d9d50887-230b-482f-d884-20dd8817edd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0-rc4\n"
     ]
    }
   ],
   "source": [
    "print (tf.__version__)\n",
    "### --------- Setup GPU ---------- ###\n",
    "\n",
    "# rtx 3080 tf 2.4.0-rc4 bug\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------- Setup BERT ---------- ###\n",
    "\n",
    "# Name of the BERT model to use\n",
    "model_name = 'bert-large-uncased'\n",
    "# bert-base-uncased\n",
    "# bert-large-uncased\n",
    "# bert-base-cased\n",
    "# bert-large-cased\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Max length of tokens\n",
    "max_length = 100\n",
    "\n",
    "epochs=20\n",
    "\n",
    "### --------- Setup logs paths ---------- ###\n",
    "lvl=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-796f5f497f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdir_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./saved_models\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-796f5f497f87>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdir_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./saved_models\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Run'"
     ]
    }
   ],
   "source": [
    "path=\"/\"+'bert-base-uncased'+\"/lvl\"+lvl+\"/\"+ str(10) +\"T_\"+str(2)+\"e/\"\n",
    "\n",
    "dir_list=os.listdir(\"./saved_models\"+path)\n",
    "\n",
    "[int(x[:3]) for x in dir_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory /home/lh/Documents/BERT_classifier/saved_models/bert-large-uncased/lvl1/100T_20e/ \n",
      "Successfully created the directory /home/lh/Documents/BERT_classifier/saved_data/bert-large-uncased/lvl1/100T_20e/ \n",
      "Successfully created the directory /home/lh/Documents/BERT_classifier/saved_data/bert-large-uncased/lvl1/100T_20e/ \n",
      "Config: /bert-large-uncased/lvl1/100T_20e/Run1\n",
      "Relative paths \n",
      " \n",
      "##### Model data #####\n",
      " \n",
      "log dir:./saved_models/bert-large-uncased/lvl1/100T_20e/Run1/logs\n",
      " \n",
      "log custom scalars dir:./saved_models/bert-large-uncased/lvl1/100T_20e/Run1/logs/custom_metrics\n",
      " \n",
      "Checkpoint dir:./saved_models/bert-large-uncased/lvl1/100T_20e/Run1/checkpoint/\n",
      " \n",
      "Saved model dir:./saved_models/bert-large-uncased/lvl1/100T_20e/Run1/model/\n",
      " \n",
      " \n",
      "##### Plots and predictions #####\n",
      " \n",
      "Plots dir:./saved_data/bert-large-uncased/lvl1/100T_20e/Run1/model.png\n",
      " \n",
      "Confusion matrix dir:./saved_data/bert-large-uncased/lvl1/100T_20e/Run1/conf.png\n",
      " \n",
      "Saved data dir:./saved_data/bert-large-uncased/lvl1/100T_20e/Run1/test_pred_raw.npz\n"
     ]
    }
   ],
   "source": [
    "### --------- Setup logs paths ---------- ###\n",
    "path=\"/\"+model_name+\"/lvl\"+lvl+\"/\"+ str(max_length) +\"T_\"+str(epochs)+\"e/\"\n",
    "\n",
    "aux_path= os.getcwd()+\"/saved_models\"+path\n",
    "try:\n",
    "    os.makedirs(aux_path)\n",
    "except OSError:\n",
    "    print (\"%s already exists\" % aux_path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % aux_path)\n",
    "\n",
    "aux_path= os.getcwd()+\"/saved_data\"+path\n",
    "try:\n",
    "    os.makedirs(aux_path)\n",
    "except OSError:\n",
    "    print (\"%s already exists\" % aux_path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % aux_path)\n",
    "    \n",
    "dir_list=os.listdir(\"./saved_models\"+path)\n",
    "if len(dir_list)==0:\n",
    "    run=1\n",
    "else:\n",
    "    aux=[int(x[-1:]) for x in dir_list]\n",
    "    aux.sort()\n",
    "    run=aux[-1]+1\n",
    "path+=\"Run\"+str(run)\n",
    "\n",
    "\n",
    "path_model=\"./saved_models\"+path\n",
    "\n",
    "logdir = path_model + \"/logs\"\n",
    "path_svae_model=path_model+\"/model/\"\n",
    "checkpoint_filepath = path_model+'/checkpoint/'\n",
    "log_dir_custom_scalars=logdir + '/custom_metrics'\n",
    "\n",
    "\n",
    "\n",
    "path_data=\"./saved_data\"+path\n",
    "try:\n",
    "    os.makedirs(path_data)\n",
    "except OSError:\n",
    "    print (\"%s already exists\" % aux_path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % aux_path)\n",
    "\n",
    "path_model_plot=path_data + \"/model.png\"\n",
    "path_confusion_mat=path_data+'/conf.png'\n",
    "path_saved_data=path_data+\"/test_pred_raw.npz\"\n",
    "\n",
    "print(\"Config: \"+ path+ \"\\nRelative paths \"+ \n",
    "      \"\\n \\n##### Model data #####\"+\n",
    "      \"\\n \\nlog dir:\" + logdir+ \n",
    "      \"\\n \\nlog custom scalars dir:\" +log_dir_custom_scalars+\n",
    "      \"\\n \\nCheckpoint dir:\" +checkpoint_filepath+\n",
    "      \"\\n \\nSaved model dir:\" +path_svae_model+\n",
    "      \"\\n \\n \\n##### Plots and predictions #####\"+\n",
    "      \"\\n \\nPlots dir:\" +path_model_plot+\n",
    "      \"\\n \\nConfusion matrix dir:\" +path_confusion_mat+\n",
    "      \"\\n \\nSaved data dir:\" +path_saved_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 18718,
     "status": "ok",
     "timestamp": 1606727647995,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "BlqZ4OoUvCba"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,f1_score,accuracy_score, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    Args:\n",
    "        cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "        class_names (array, shape = [n]): String names of the integer classe\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix, accuracy {:.4f} \\n f1 Score {:.4f}\".format(accuracy_score,f1_score))\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    \n",
    "    # Compute the labels from the normalized confusion matrix.\n",
    "    labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "executionInfo": {
     "elapsed": 19562,
     "status": "ok",
     "timestamp": 1606727581663,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "2ylPg1GFjaYs",
    "outputId": "c3aaa6b1-a412-4c24-f08e-9cfda702a8ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['baby products' 'beauty' 'grocery gourmet food' 'health personal care'\n",
      " 'pet supplies' 'toys games']\n",
      "                                                Text  Cat1  \\\n",
      "0  The description and photo on this product need...     2   \n",
      "1  This was a great book!!!! It is well thought t...     5   \n",
      "2  I am a first year teacher, teaching 5th grade....     5   \n",
      "3  I got the book at my bookfair at school lookin...     5   \n",
      "4  Hi! I'm Martine Redman and I created this puzz...     5   \n",
      "\n",
      "             Cat1_label  \n",
      "0  grocery gourmet food  \n",
      "1            toys games  \n",
      "2            toys games  \n",
      "3            toys games  \n",
      "4            toys games  \n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "### --------- Import data --------- ###\n",
    "\n",
    "# Import data from csv\n",
    "data = pd.read_csv(\"amazon/train.csv\")\n",
    "test = pd.read_csv(\"amazon/test.csv\")\n",
    "\n",
    "# Select required columns\n",
    "data = data[['Text', 'Cat1']]\n",
    "test = test[['Text', 'Cat1']]\n",
    "\n",
    "# Training data\n",
    "# Set model output as categorical and save in new label col\n",
    "data['Cat1_label'] = pd.Categorical(data['Cat1'])\n",
    "# Transform your output to numeric\n",
    "data['Cat1'] = data['Cat1_label'].cat.codes\n",
    "\n",
    "\n",
    "# Setup test data for logging\n",
    "# Set model output as categorical and save in new label col\n",
    "test['Cat1_label'] = pd.Categorical(test['Cat1'])\n",
    "# Transform your output to numeric\n",
    "test['Cat1'] = test['Cat1_label'].cat.codes\n",
    "\n",
    "class_names =np.unique(test['Cat1_label'])\n",
    "print(\"Class names:\",class_names)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3878,
     "status": "ok",
     "timestamp": 1606727631581,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "3Bgjvw6vjcvi",
    "outputId": "61ff6067-d4ae-426b-c89e-47fe8e822b8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "### --------- Load BERT ---------- ###\n",
    "\n",
    "# Load transformers config and set output_hidden_states to False\n",
    "config = BertConfig.from_pretrained(model_name)\n",
    "config.output_hidden_states = False\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
    "\n",
    "# Load the Transformers BERT model\n",
    "transformer_model = TFBertModel.from_pretrained(model_name, config = config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6529,
     "status": "ok",
     "timestamp": 1606727634638,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "VAK0KYMnsImo",
    "outputId": "057cbd0f-696f-421b-bff8-8cdbc057390a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_MultiClass\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attention_mask (InputLayer)     [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids (InputLayer)          [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 335141888   attention_mask[0][0]             \n",
      "                                                                 input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pooled_output (Dropout)         (None, 1024)         0           bert[1][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "Cat1 (Dense)                    (None, 6)            6150        pooled_output[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 335,148,038\n",
      "Trainable params: 335,148,038\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### ------- Build the model ------- ###\n",
    "\n",
    "# TF Keras documentation: https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "\n",
    "# Load the MainLayer\n",
    "bert = transformer_model.layers[0]\n",
    "\n",
    "# Build your model input\n",
    "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
    "attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32') # Ignores padded part of sentences\n",
    "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "# Load the Transformers BERT model as a layer in a Keras model\n",
    "bert_model = bert(inputs)[1]\n",
    "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "pooled_output = dropout(bert_model, training=False)\n",
    "\n",
    "# Then build your model output\n",
    "output = Dense(units=len(data.Cat1_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='Cat1')(pooled_output)\n",
    "\n",
    "# And combine it all in a model object\n",
    "model = Model(inputs=inputs, outputs=output, name='BERT_MultiClass')\n",
    "\n",
    "# Take a look at the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 19352,
     "status": "ok",
     "timestamp": 1606727647990,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "CIpi9FYVjdV1"
   },
   "outputs": [],
   "source": [
    "### ------- Setup training ------- ###\n",
    "\n",
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-05,\n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss = CategoricalCrossentropy(from_logits = True)\n",
    "metric = CategoricalAccuracy('accuracy')\n",
    "     \n",
    "        \n",
    "        \n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)\n",
    "\n",
    "# Ready target data for the model\n",
    "y_Cat1 = to_categorical(data['Cat1'])\n",
    "\n",
    "# Ready target test data for logging\n",
    "test_y_cat1 = to_categorical(test['Cat1'])\n",
    " \n",
    "# Tokenize the input (takes some time) for training and test (for logging) data\n",
    "x = tokenizer(\n",
    "    text=data['Text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "\n",
    "test_x = tokenizer(\n",
    "    text=test['Text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------- Callbacks ------- ###\n",
    "# Tensorboard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1, write_graph=False, write_images=True, profile_batch='2,9')\n",
    "#Custom summary writer for custom scalars and confusion matrix\n",
    "file_writer_cm = tf.summary.create_file_writer(log_dir_custom_scalars)\n",
    "\n",
    "#Save weights of best val_accuracy \n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    # Use the model to predict the values from the validation dataset.\n",
    "    test_pred_raw = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = sklearn.metrics.confusion_matrix(test['Cat1'] , test_pred)\n",
    "    \n",
    "    f1_score= sklearn.metrics.f1_score(test['Cat1'], test_pred, average='macro')\n",
    "    accuracy_score=sklearn.metrics.accuracy_score(test['Cat1'], test_pred)\n",
    "    \n",
    "    accu.append(accuracy_score)\n",
    "    f1_score_list.append(f1_score)\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    figure = plot_confusion_matrix(cm,f1_score,accuracy_score, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "        tf.summary.scalar(\"Test accuracy\", accuracy_score, step=epoch)\n",
    "        tf.summary.scalar(\"f1_score\", f1_score, step=epoch)\n",
    "\n",
    "# Define the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlhKv6gmxOOP",
    "outputId": "e317786e-e3a9-4677-89b7-71627c0f3b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2286/2286 [==============================] - 663s 282ms/step - loss: 0.6159 - accuracy: 0.7808 - val_loss: 0.4662 - val_accuracy: 0.8426\n",
      "Epoch 2/20\n",
      "2286/2286 [==============================] - 640s 280ms/step - loss: 0.2743 - accuracy: 0.9082 - val_loss: 0.4682 - val_accuracy: 0.8512\n",
      "Epoch 3/20\n",
      "2286/2286 [==============================] - 637s 279ms/step - loss: 0.2210 - accuracy: 0.9283 - val_loss: 0.4829 - val_accuracy: 0.8514\n",
      "Epoch 4/20\n",
      "2286/2286 [==============================] - 639s 279ms/step - loss: 0.1881 - accuracy: 0.9387 - val_loss: 0.4901 - val_accuracy: 0.8519\n",
      "Epoch 5/20\n",
      "2286/2286 [==============================] - 640s 280ms/step - loss: 0.1812 - accuracy: 0.9390 - val_loss: 0.5038 - val_accuracy: 0.8529\n",
      "Epoch 6/20\n",
      "2286/2286 [==============================] - 640s 280ms/step - loss: 0.1663 - accuracy: 0.9462 - val_loss: 0.5126 - val_accuracy: 0.8521\n",
      "Epoch 7/20\n",
      "2286/2286 [==============================] - 641s 280ms/step - loss: 0.1557 - accuracy: 0.9498 - val_loss: 0.5215 - val_accuracy: 0.8526\n",
      "Epoch 8/20\n",
      "2286/2286 [==============================] - 642s 281ms/step - loss: 0.1391 - accuracy: 0.9576 - val_loss: 0.5317 - val_accuracy: 0.8533\n",
      "Epoch 9/20\n",
      "2286/2286 [==============================] - 646s 283ms/step - loss: 0.1367 - accuracy: 0.9581 - val_loss: 0.5402 - val_accuracy: 0.8519\n",
      "Epoch 10/20\n",
      "2286/2286 [==============================] - 646s 282ms/step - loss: 0.1263 - accuracy: 0.9608 - val_loss: 0.5429 - val_accuracy: 0.8524\n",
      "Epoch 11/20\n",
      "2286/2286 [==============================] - 647s 283ms/step - loss: 0.1250 - accuracy: 0.9618 - val_loss: 0.5530 - val_accuracy: 0.8500\n",
      "Epoch 12/20\n",
      "2286/2286 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9632"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-66a21374cfdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m### ------- Train the model ------- ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m history=model.fit(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_Cat1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1131\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accu=[]\n",
    "f1_score_list=[]\n",
    "### ------- Train the model ------- ###\n",
    "# Batch size table rtx 3080\n",
    "#100T base-uncased: 50\n",
    "#100T large-uncase: 14\n",
    "\n",
    "# Fit the model\n",
    "history=model.fit(\n",
    "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "    y=y_Cat1,\n",
    "    validation_split=0.2,\n",
    "    batch_size=14, #100T base-uncased: 50/ 100T large-uncase: 14\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback, cm_callback,model_checkpoint_callback]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAlV8ode1Btd"
   },
   "outputs": [],
   "source": [
    "# Load the best weights and save the model\n",
    "model.load_weights(checkpoint_filepath)\n",
    "model.save(path_svae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TO-pUAoCoHox"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=path_model_plot,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37287,
     "status": "aborted",
     "timestamp": 1606727674757,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "TLOgxtjpBDAI"
   },
   "outputs": [],
   "source": [
    "### ----- Evaluate the model ------ ###\n",
    "\n",
    "test_pred_raw = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']}, verbose=1) \n",
    "train_pred_raw = model.predict(x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']}, verbose=1) \n",
    "\n",
    "test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "# Calculate the confusion matrix.\n",
    "cm = sklearn.metrics.confusion_matrix(test['Cat1'] , test_pred)\n",
    "cm[np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2) < 0.05] = 0\n",
    "\n",
    "f1_score= sklearn.metrics.f1_score(test['Cat1'], test_pred, average='macro')\n",
    "accuracy_score=sklearn.metrics.accuracy_score(test['Cat1'], test_pred)\n",
    "# Log the confusion matrix as an image summary.\n",
    "figure = plot_confusion_matrix(cm,f1_score,accuracy_score, class_names=class_names)\n",
    "\n",
    "figure.savefig(path_confusion_mat)\n",
    "plt.show() #plt.close(figure)\n",
    "print(\"F1 macro score\", f1_score)\n",
    "print(\"accuracy score\", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35939,
     "status": "aborted",
     "timestamp": 1606727674771,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "K1R5gLG87zA6"
   },
   "outputs": [],
   "source": [
    "report=sklearn.metrics.classification_report(test['Cat1'], test_pred, target_names=class_names, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35332,
     "status": "aborted",
     "timestamp": 1606727674772,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "G7NjT0RWBDk7"
   },
   "outputs": [],
   "source": [
    "#Save data for hierarchical runs\n",
    "np.savez(path_saved_data, test_pred_raw=test_pred_raw, f1_score=f1_score, accuracy_score=accuracy_score,train_pred_raw=train_pred_raw, report=report, accu_list=np.array(accu), f1_score_list=np.array(f1_score_list), history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lh/miniconda3/envs/AMDML/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "512T_10e_Classifier_lvl1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
