{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 19027,
     "status": "ok",
     "timestamp": 1606727581094,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "SkaBphd5jIlX"
   },
   "outputs": [],
   "source": [
    "### -------- Load libraries ------- ###\n",
    "\n",
    "# Load Huggingface transformers\n",
    "from transformers import TFBertModel, BertConfig, BertTokenizerFast\n",
    "\n",
    "# Then what you need from tensorflow.keras\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# And pandas for data import + sklearn because you allways need sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import itertools\n",
    "import io\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19015,
     "status": "ok",
     "timestamp": 1606727581096,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "qfS1HOOi8seS",
    "outputId": "d9d50887-230b-482f-d884-20dd8817edd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0-rc4\n"
     ]
    }
   ],
   "source": [
    "print (tf.__version__)\n",
    "### --------- Setup GPU ---------- ###\n",
    "\n",
    "# rtx 3080 tf 2.4.0-rc4 bug\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------- Setup BERT ---------- ###\n",
    "\n",
    "# Name of the BERT model to use\n",
    "model_name = 'bert-large-uncased'\n",
    "# bert-base-uncased\n",
    "# bert-large-uncased\n",
    "# bert-base-cased\n",
    "# bert-large-cased\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Max length of tokens\n",
    "max_length = 100\n",
    "\n",
    "epochs=20\n",
    "\n",
    "### --------- Setup logs paths ---------- ###\n",
    "lvl=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory /home/lh/Documents/BERT_classifier/saved_models/lvl1/bert-large-uncased/100T_20e/ \n",
      "Successfully created the directory /home/lh/Documents/BERT_classifier/saved_data/lvl1/bert-large-uncased/100T_20e/ \n",
      "Successfully created the directory /home/lh/Documents/BERT_classifier/saved_data/lvl1/bert-large-uncased/100T_20e/ \n",
      "Config: /lvl1/bert-large-uncased/100T_20e/Run1\n",
      "Relative paths \n",
      " \n",
      "##### Model data #####\n",
      " \n",
      "log dir:./saved_models/lvl1/bert-large-uncased/100T_20e/Run1/logs\n",
      " \n",
      "log custom scalars dir:./saved_models/lvl1/bert-large-uncased/100T_20e/Run1/logs/custom_metrics\n",
      " \n",
      "Checkpoint dir:./saved_models/lvl1/bert-large-uncased/100T_20e/Run1/checkpoint/\n",
      " \n",
      "Saved model dir:./saved_models/lvl1/bert-large-uncased/100T_20e/Run1/model/\n",
      " \n",
      " \n",
      "##### Plots and predictions #####\n",
      " \n",
      "Plots dir:./saved_data/lvl1/bert-large-uncased/100T_20e/Run1/model.png\n",
      " \n",
      "Confusion matrix dir:./saved_data/lvl1/bert-large-uncased/100T_20e/Run1/conf.png\n",
      " \n",
      "Saved data dir:./saved_data/lvl1/bert-large-uncased/100T_20e/Run1/test_pred_raw.npz\n"
     ]
    }
   ],
   "source": [
    "### --------- Setup logs paths ---------- ###\n",
    "path=\"/lvl\"+lvl+\"/\"+model_name+\"/\"+ str(max_length) +\"T_\"+str(epochs)+\"e/\"\n",
    "\n",
    "aux_path= os.getcwd()+\"/saved_models\"+path\n",
    "try:\n",
    "    os.makedirs(aux_path)\n",
    "except OSError:\n",
    "    print (\"%s already exists\" % aux_path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % aux_path)\n",
    "\n",
    "aux_path= os.getcwd()+\"/saved_data\"+path\n",
    "try:\n",
    "    os.makedirs(aux_path)\n",
    "except OSError:\n",
    "    print (\"%s already exists\" % aux_path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % aux_path)\n",
    "    \n",
    "dir_list=os.listdir(\"./saved_models\"+path)\n",
    "if len(dir_list)==0:\n",
    "    run=1\n",
    "else:\n",
    "    aux=[int(x[-1:]) for x in dir_list]\n",
    "    aux.sort()\n",
    "    run=aux[-1]+1\n",
    "path+=\"Run\"+str(run)\n",
    "\n",
    "\n",
    "path_model=\"./saved_models\"+path\n",
    "\n",
    "logdir = path_model + \"/logs\"\n",
    "path_svae_model=path_model+\"/model/\"\n",
    "checkpoint_filepath = path_model+'/checkpoint/'\n",
    "log_dir_custom_scalars=logdir + '/custom_metrics'\n",
    "\n",
    "\n",
    "\n",
    "path_data=\"./saved_data\"+path\n",
    "try:\n",
    "    os.makedirs(path_data)\n",
    "except OSError:\n",
    "    print (\"%s already exists\" % aux_path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % aux_path)\n",
    "\n",
    "path_model_plot=path_data + \"/model.png\"\n",
    "path_confusion_mat=path_data+'/conf.png'\n",
    "path_saved_data=path_data+\"/test_pred_raw.npz\"\n",
    "\n",
    "print(\"Config: \"+ path+ \"\\nRelative paths \"+ \n",
    "      \"\\n \\n##### Model data #####\"+\n",
    "      \"\\n \\nlog dir:\" + logdir+ \n",
    "      \"\\n \\nlog custom scalars dir:\" +log_dir_custom_scalars+\n",
    "      \"\\n \\nCheckpoint dir:\" +checkpoint_filepath+\n",
    "      \"\\n \\nSaved model dir:\" +path_svae_model+\n",
    "      \"\\n \\n \\n##### Plots and predictions #####\"+\n",
    "      \"\\n \\nPlots dir:\" +path_model_plot+\n",
    "      \"\\n \\nConfusion matrix dir:\" +path_confusion_mat+\n",
    "      \"\\n \\nSaved data dir:\" +path_saved_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 18718,
     "status": "ok",
     "timestamp": 1606727647995,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "BlqZ4OoUvCba"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,f1_score,accuracy_score, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    Args:\n",
    "        cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "        class_names (array, shape = [n]): String names of the integer classe\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix, accuracy {:.4f} \\n f1 Score {:.4f}\".format(accuracy_score,f1_score))\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    \n",
    "    # Compute the labels from the normalized confusion matrix.\n",
    "    labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "executionInfo": {
     "elapsed": 19562,
     "status": "ok",
     "timestamp": 1606727581663,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "2ylPg1GFjaYs",
    "outputId": "c3aaa6b1-a412-4c24-f08e-9cfda702a8ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['baby products' 'beauty' 'grocery gourmet food' 'health personal care'\n",
      " 'pet supplies' 'toys games']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Cat1</th>\n",
       "      <th>Cat1_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The description and photo on this product need...</td>\n",
       "      <td>2</td>\n",
       "      <td>grocery gourmet food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was a great book!!!! It is well thought t...</td>\n",
       "      <td>5</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a first year teacher, teaching 5th grade....</td>\n",
       "      <td>5</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got the book at my bookfair at school lookin...</td>\n",
       "      <td>5</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! I'm Martine Redman and I created this puzz...</td>\n",
       "      <td>5</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Cat1  \\\n",
       "0  The description and photo on this product need...     2   \n",
       "1  This was a great book!!!! It is well thought t...     5   \n",
       "2  I am a first year teacher, teaching 5th grade....     5   \n",
       "3  I got the book at my bookfair at school lookin...     5   \n",
       "4  Hi! I'm Martine Redman and I created this puzz...     5   \n",
       "\n",
       "             Cat1_label  \n",
       "0  grocery gourmet food  \n",
       "1            toys games  \n",
       "2            toys games  \n",
       "3            toys games  \n",
       "4            toys games  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################\n",
    "### --------- Import data --------- ###\n",
    "\n",
    "# Import data from csv\n",
    "data = pd.read_csv(\"amazon/train.csv\")\n",
    "test = pd.read_csv(\"amazon/test.csv\")\n",
    "\n",
    "# Select required columns\n",
    "data = data[['Text', 'Cat1']]\n",
    "test = test[['Text', 'Cat1']]\n",
    "\n",
    "# Training data\n",
    "# Set model output as categorical and save in new label col\n",
    "data['Cat1_label'] = pd.Categorical(data['Cat1'])\n",
    "# Transform your output to numeric\n",
    "data['Cat1'] = data['Cat1_label'].cat.codes\n",
    "\n",
    "\n",
    "# Setup test data for logging\n",
    "# Set model output as categorical and save in new label col\n",
    "test['Cat1_label'] = pd.Categorical(test['Cat1'])\n",
    "# Transform your output to numeric\n",
    "test['Cat1'] = test['Cat1_label'].cat.codes\n",
    "\n",
    "class_names =np.unique(test['Cat1_label'])\n",
    "print(\"Class names:\",class_names)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3878,
     "status": "ok",
     "timestamp": 1606727631581,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "3Bgjvw6vjcvi",
    "outputId": "61ff6067-d4ae-426b-c89e-47fe8e822b8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "### --------- Load BERT ---------- ###\n",
    "\n",
    "# Load transformers config and set output_hidden_states to False\n",
    "config = BertConfig.from_pretrained(model_name)\n",
    "config.output_hidden_states = False\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
    "\n",
    "# Load the Transformers BERT model\n",
    "transformer_model = TFBertModel.from_pretrained(model_name, config = config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6529,
     "status": "ok",
     "timestamp": 1606727634638,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "VAK0KYMnsImo",
    "outputId": "057cbd0f-696f-421b-bff8-8cdbc057390a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_MultiClass\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attention_mask (InputLayer)     [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids (InputLayer)          [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 335141888   attention_mask[0][0]             \n",
      "                                                                 input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pooled_output (Dropout)         (None, 1024)         0           bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "Cat1 (Dense)                    (None, 6)            6150        pooled_output[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 335,148,038\n",
      "Trainable params: 335,148,038\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### ------- Build the model ------- ###\n",
    "\n",
    "# TF Keras documentation: https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "\n",
    "# Load the MainLayer\n",
    "bert = transformer_model.layers[0]\n",
    "\n",
    "# Build your model input\n",
    "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
    "attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32') # Ignores padded part of sentences\n",
    "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "# Load the Transformers BERT model as a layer in a Keras model\n",
    "bert_model = bert(inputs)[1]\n",
    "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "pooled_output = dropout(bert_model, training=False)\n",
    "\n",
    "# Then build your model output\n",
    "output = Dense(units=len(data.Cat1_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='Cat1')(pooled_output)\n",
    "\n",
    "# And combine it all in a model object\n",
    "model = Model(inputs=inputs, outputs=output, name='BERT_MultiClass')\n",
    "\n",
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 19352,
     "status": "ok",
     "timestamp": 1606727647990,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "CIpi9FYVjdV1"
   },
   "outputs": [],
   "source": [
    "### ------- Setup training ------- ###\n",
    "\n",
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-05,\n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss = CategoricalCrossentropy(from_logits = True)\n",
    "metric = CategoricalAccuracy('accuracy')\n",
    "     \n",
    "        \n",
    "        \n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)\n",
    "\n",
    "# Ready target data for the model\n",
    "y_Cat1 = to_categorical(data['Cat1'])\n",
    "\n",
    "# Ready target test data for logging\n",
    "test_y_cat1 = to_categorical(test['Cat1'])\n",
    " \n",
    "# Tokenize the input (takes some time) for training and test (for logging) data\n",
    "x = tokenizer(\n",
    "    text=data['Text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "\n",
    "test_x = tokenizer(\n",
    "    text=test['Text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------- Callbacks ------- ###\n",
    "# Tensorboard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1, write_graph=False, write_images=True, profile_batch='2,9')\n",
    "#Custom summary writer for custom scalars and confusion matrix\n",
    "file_writer_cm = tf.summary.create_file_writer(log_dir_custom_scalars)\n",
    "\n",
    "#Save weights of best val_accuracy \n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    # Use the model to predict the values from the validation dataset.\n",
    "    test_pred_raw = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = sklearn.metrics.confusion_matrix(test['Cat1'] , test_pred)\n",
    "    \n",
    "    f1_score= sklearn.metrics.f1_score(test['Cat1'], test_pred, average='macro')\n",
    "    accuracy_score=sklearn.metrics.accuracy_score(test['Cat1'], test_pred)\n",
    "    \n",
    "    accu.append(accuracy_score)\n",
    "    f1_score_list.append(f1_score)\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    figure = plot_confusion_matrix(cm,f1_score,accuracy_score, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "        tf.summary.scalar(\"Test accuracy\", accuracy_score, step=epoch)\n",
    "        tf.summary.scalar(\"f1_score\", f1_score, step=epoch)\n",
    "\n",
    "# Define the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlhKv6gmxOOP",
    "outputId": "e317786e-e3a9-4677-89b7-71627c0f3b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2286/2286 [==============================] - 644s 282ms/step - loss: 0.4126 - accuracy: 0.8581 - val_loss: 0.4481 - val_accuracy: 0.8509\n",
      "Epoch 2/20\n",
      "2286/2286 [==============================] - 637s 278ms/step - loss: 0.2524 - accuracy: 0.9158 - val_loss: 0.4600 - val_accuracy: 0.8501\n",
      "Epoch 3/20\n",
      "2286/2286 [==============================] - 671s 293ms/step - loss: 0.2087 - accuracy: 0.9316 - val_loss: 0.4721 - val_accuracy: 0.8534\n"
     ]
    }
   ],
   "source": [
    "accu=[]\n",
    "f1_score_list=[]\n",
    "### ------- Train the model ------- ###\n",
    "# Fit the model\n",
    "history=model.fit(\n",
    "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "    y=y_Cat1,\n",
    "    validation_split=0.2,\n",
    "    batch_size=14, #100T base-uncased: 50/ 100T large-uncase: 14\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback, cm_callback,model_checkpoint_callback]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAlV8ode1Btd"
   },
   "outputs": [],
   "source": [
    "# Load the best weights and save the model\n",
    "model.load_weights(checkpoint_filepath)\n",
    "model.save(path_svae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TO-pUAoCoHox"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=path_model_plot,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37287,
     "status": "aborted",
     "timestamp": 1606727674757,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "TLOgxtjpBDAI"
   },
   "outputs": [],
   "source": [
    "### ----- Evaluate the model ------ ###\n",
    "\n",
    "test_pred_raw = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']}, verbose=1) \n",
    "train_pred_raw = model.predict(x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']}, verbose=1) \n",
    "\n",
    "test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "# Calculate the confusion matrix.\n",
    "cm = sklearn.metrics.confusion_matrix(test['Cat1'] , test_pred)\n",
    "cm[np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2) < 0.05] = 0\n",
    "\n",
    "f1_score= sklearn.metrics.f1_score(test['Cat1'], test_pred, average='macro')\n",
    "accuracy_score=sklearn.metrics.accuracy_score(test['Cat1'], test_pred)\n",
    "# Log the confusion matrix as an image summary.\n",
    "figure = plot_confusion_matrix(cm,f1_score,accuracy_score, class_names=class_names)\n",
    "\n",
    "figure.savefig(path_confusion_mat)\n",
    "plt.show() #plt.close(figure)\n",
    "print(\"F1 macro score\", f1_score)\n",
    "print(\"accuracy score\", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35939,
     "status": "aborted",
     "timestamp": 1606727674771,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "K1R5gLG87zA6"
   },
   "outputs": [],
   "source": [
    "report=sklearn.metrics.classification_report(test['Cat1'], test_pred, target_names=class_names, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35332,
     "status": "aborted",
     "timestamp": 1606727674772,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "G7NjT0RWBDk7"
   },
   "outputs": [],
   "source": [
    "#Save data for hierarchical runs\n",
    "np.savez(path_saved_data, test_pred_raw=test_pred_raw, f1_score=f1_score, accuracy_score=accuracy_score,train_pred_raw=train_pred_raw, report=report, accu_list=np.array(accu), f1_score_list=np.array(f1_score_list), history=history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "512T_10e_Classifier_lvl1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
