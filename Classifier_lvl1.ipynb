{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 19027,
     "status": "ok",
     "timestamp": 1606727581094,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "SkaBphd5jIlX"
   },
   "outputs": [],
   "source": [
    "### -------- Load libraries ------- ###\n",
    "\n",
    "# Load Huggingface transformers\n",
    "from transformers import TFBertModel, BertConfig, BertTokenizerFast,TFBertForSequenceClassification\n",
    "\n",
    "# Then what you need from tensorflow.keras\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# And pandas for data import + sklearn because you allways need sklearn\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import itertools\n",
    "import io\n",
    "import os\n",
    "import yaml\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19015,
     "status": "ok",
     "timestamp": 1606727581096,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "qfS1HOOi8seS",
    "outputId": "d9d50887-230b-482f-d884-20dd8817edd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0-rc4\n"
     ]
    }
   ],
   "source": [
    "print (tf.__version__)\n",
    "### --------- Setup GPU ---------- ###\n",
    "\n",
    "# rtx 3080 tf 2.4.0-rc4 bug\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------- Setup BERT ---------- ###\n",
    "\n",
    "# Name of the BERT model to use\n",
    "model_name = 'bert-large-uncased'\n",
    "# bert-base-uncased\n",
    "# bert-large-uncased\n",
    "# bert-base-cased\n",
    "# bert-large-cased\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Max length of tokens\n",
    "max_length = 100\n",
    "\n",
    "epochs=20\n",
    "\n",
    "### --------- Setup logs paths ---------- ###\n",
    "lvl=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/\"+'bert-base-uncased'+\"/lvl\"+lvl+\"/\"+ str(10) +\"T_\"+str(2)+\"e/\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lh/Documents/BERT_classifier/saved_models/bert-large-uncased/lvl1/100T_20e/ already exists\n",
      "/home/lh/Documents/BERT_classifier/saved_data/bert-large-uncased/lvl1/100T_20e/ already exists\n",
      "/home/lh/Documents/BERT_classifier/saved_data/bert-large-uncased/lvl1/100T_20e/ already exists\n",
      "Config: /bert-large-uncased/lvl1/100T_20e/Run4\n",
      "Relative paths \n",
      " \n",
      "##### Model data #####\n",
      " \n",
      "log dir:./saved_models/bert-large-uncased/lvl1/100T_20e/Run4/logs\n",
      " \n",
      "log custom scalars dir:./saved_models/bert-large-uncased/lvl1/100T_20e/Run4/logs/custom_metrics\n",
      " \n",
      "Checkpoint dir:./saved_models/bert-large-uncased/lvl1/100T_20e/Run4/checkpoint/\n",
      " \n",
      "Saved model dir:./saved_models/bert-large-uncased/lvl1/100T_20e/Run4/model/\n",
      " \n",
      " \n",
      "##### Plots and predictions #####\n",
      " \n",
      "Plots dir:./saved_data/bert-large-uncased/lvl1/100T_20e/Run4/model.png\n",
      " \n",
      "Confusion matrix dir:./saved_data/bert-large-uncased/lvl1/100T_20e/Run4/conf.png\n",
      " \n",
      "Saved data dir:./saved_data/bert-large-uncased/lvl1/100T_20e/Run4/test_pred_raw.npz\n"
     ]
    }
   ],
   "source": [
    "### --------- Setup logs paths ---------- ###\n",
    "path=\"/\"+model_name+\"/lvl\"+lvl+\"/\"+ str(max_length) +\"T_\"+str(epochs)+\"e/\"\n",
    "\n",
    "aux_path= os.getcwd()+\"/saved_models\"+path\n",
    "try:\n",
    "    os.makedirs(aux_path)\n",
    "except OSError:\n",
    "    print (\"%s already exists\" % aux_path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % aux_path)\n",
    "\n",
    "aux_path= os.getcwd()+\"/saved_data\"+path\n",
    "try:\n",
    "    os.makedirs(aux_path)\n",
    "except OSError:\n",
    "    print (\"%s already exists\" % aux_path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % aux_path)\n",
    "    \n",
    "dir_list=os.listdir(\"./saved_models\"+path)\n",
    "if len(dir_list)==0:\n",
    "    run=1\n",
    "else:\n",
    "    aux=[int(x[-1:]) for x in dir_list]\n",
    "    aux.sort()\n",
    "    run=aux[-1]+1\n",
    "path+=\"Run\"+str(run)\n",
    "\n",
    "\n",
    "path_model=\"./saved_models\"+path\n",
    "\n",
    "logdir = path_model + \"/logs\"\n",
    "path_svae_model=path_model+\"/model/\"\n",
    "checkpoint_filepath = path_model+'/checkpoint/'\n",
    "log_dir_custom_scalars=logdir + '/custom_metrics'\n",
    "\n",
    "\n",
    "\n",
    "path_data=\"./saved_data\"+path\n",
    "try:\n",
    "    os.makedirs(path_data)\n",
    "except OSError:\n",
    "    print (\"%s already exists\" % aux_path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % aux_path)\n",
    "\n",
    "path_model_plot=path_data + \"/model.png\"\n",
    "path_confusion_mat=path_data+'/conf.png'\n",
    "path_saved_data=path_data+\"/test_pred_raw.npz\"\n",
    "\n",
    "print(\"Config: \"+ path+ \"\\nRelative paths \"+ \n",
    "      \"\\n \\n##### Model data #####\"+\n",
    "      \"\\n \\nlog dir:\" + logdir+ \n",
    "      \"\\n \\nlog custom scalars dir:\" +log_dir_custom_scalars+\n",
    "      \"\\n \\nCheckpoint dir:\" +checkpoint_filepath+\n",
    "      \"\\n \\nSaved model dir:\" +path_svae_model+\n",
    "      \"\\n \\n \\n##### Plots and predictions #####\"+\n",
    "      \"\\n \\nPlots dir:\" +path_model_plot+\n",
    "      \"\\n \\nConfusion matrix dir:\" +path_confusion_mat+\n",
    "      \"\\n \\nSaved data dir:\" +path_saved_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 18718,
     "status": "ok",
     "timestamp": 1606727647995,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "BlqZ4OoUvCba"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,f1_score,accuracy_score, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    Args:\n",
    "        cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "        class_names (array, shape = [n]): String names of the integer classe\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix, accuracy {:.4f} \\n f1 Score {:.4f}\".format(accuracy_score,f1_score))\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    \n",
    "    # Compute the labels from the normalized confusion matrix.\n",
    "    labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "executionInfo": {
     "elapsed": 19562,
     "status": "ok",
     "timestamp": 1606727581663,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "2ylPg1GFjaYs",
    "outputId": "c3aaa6b1-a412-4c24-f08e-9cfda702a8ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['baby products' 'beauty' 'grocery gourmet food' 'health personal care'\n",
      " 'pet supplies' 'toys games']\n",
      "                                                Text  Cat1  \\\n",
      "0  The description and photo on this product need...     2   \n",
      "1  This was a great book!!!! It is well thought t...     5   \n",
      "2  I am a first year teacher, teaching 5th grade....     5   \n",
      "3  I got the book at my bookfair at school lookin...     5   \n",
      "4  Hi! I'm Martine Redman and I created this puzz...     5   \n",
      "\n",
      "             Cat1_label  \n",
      "0  grocery gourmet food  \n",
      "1            toys games  \n",
      "2            toys games  \n",
      "3            toys games  \n",
      "4            toys games  \n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "### --------- Import data --------- ###\n",
    "\n",
    "# Import data from csv\n",
    "data = pd.read_csv(\"amazon/train.csv\")\n",
    "test = pd.read_csv(\"amazon/test.csv\")\n",
    "\n",
    "# Select required columns\n",
    "data = data[['Text', 'Cat1']]\n",
    "test = test[['Text', 'Cat1']]\n",
    "\n",
    "# Training data\n",
    "# Set model output as categorical and save in new label col\n",
    "data['Cat1_label'] = pd.Categorical(data['Cat1'])\n",
    "# Transform your output to numeric\n",
    "data['Cat1'] = data['Cat1_label'].cat.codes\n",
    "\n",
    "\n",
    "# Setup test data for logging\n",
    "# Set model output as categorical and save in new label col\n",
    "test['Cat1_label'] = pd.Categorical(test['Cat1'])\n",
    "# Transform your output to numeric\n",
    "test['Cat1'] = test['Cat1_label'].cat.codes\n",
    "\n",
    "class_names =np.unique(test['Cat1_label'])\n",
    "print(\"Class names:\",class_names)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3878,
     "status": "ok",
     "timestamp": 1606727631581,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "3Bgjvw6vjcvi",
    "outputId": "61ff6067-d4ae-426b-c89e-47fe8e822b8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier', 'dropout_113']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "### --------- Load BERT ---------- ###\n",
    "\n",
    "# Load transformers config and set output_hidden_states to False\n",
    "config = BertConfig.from_pretrained(model_name)\n",
    "config.output_hidden_states = False\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
    "\n",
    "# Load the Transformers BERT model\n",
    "#transformer_model = TFBertModel.from_pretrained(model_name, config = config)\n",
    "transformer_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  4614      \n",
      "=================================================================\n",
      "Total params: 109,486,854\n",
      "Trainable params: 109,486,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6529,
     "status": "ok",
     "timestamp": 1606727634638,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "VAK0KYMnsImo",
    "outputId": "057cbd0f-696f-421b-bff8-8cdbc057390a"
   },
   "outputs": [],
   "source": [
    "### ------- Build the model ------- ###\n",
    "\n",
    "# TF Keras documentation: https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "\n",
    "# Load the MainLayer\n",
    "bert = transformer_model.layers[0]\n",
    "\n",
    "# Build your model input\n",
    "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
    "attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32') # Ignores padded part of sentences\n",
    "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6529,
     "status": "ok",
     "timestamp": 1606727634638,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "VAK0KYMnsImo",
    "outputId": "057cbd0f-696f-421b-bff8-8cdbc057390a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_MultiClass\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attention_mask (InputLayer)     [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids (InputLayer)          [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_for_sequence_classifica TFSequenceClassifier 109486854   attention_mask[0][0]             \n",
      "                                                                 input_ids[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,486,854\n",
      "Trainable params: 109,486,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the Transformers BERT model as a layer in a Keras model\n",
    "output = transformer_model(inputs, training=True)\n",
    "#dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "#pooled_output = dropout(bert_model, training=False)\n",
    "\n",
    "# Then build your model output\n",
    "#output = Dense(units=len(data.Cat1_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='Cat1')(pooled_output)\n",
    "\n",
    "# And combine it all in a model object\n",
    "model = Model(inputs=inputs, outputs=output, name='BERT_MultiClass')\n",
    "\n",
    "# Take a look at the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 19352,
     "status": "ok",
     "timestamp": 1606727647990,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "CIpi9FYVjdV1"
   },
   "outputs": [],
   "source": [
    "### ------- Setup training ------- ###\n",
    "\n",
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-05,\n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "# Set loss and metrics\n",
    "loss = CategoricalCrossentropy(from_logits = True)\n",
    "metric = CategoricalAccuracy('accuracy')\n",
    "     \n",
    "        \n",
    "        \n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)\n",
    "\n",
    "# Ready target data for the model\n",
    "y_Cat1 = to_categorical(data['Cat1'])\n",
    "\n",
    "# Ready target test data for logging\n",
    "test_y_cat1 = to_categorical(test['Cat1'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 19352,
     "status": "ok",
     "timestamp": 1606727647990,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "CIpi9FYVjdV1"
   },
   "outputs": [],
   "source": [
    "# Tokenize the input (takes some time) for training and test (for logging) data\n",
    "x = tokenizer(\n",
    "    text=data['Text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "\n",
    "test_x = tokenizer(\n",
    "    text=test['Text'].to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------- Callbacks ------- ###\n",
    "# Tensorboard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1, write_graph=False, write_images=True, profile_batch='2,9')\n",
    "#Custom summary writer for custom scalars and confusion matrix\n",
    "file_writer_cm = tf.summary.create_file_writer(log_dir_custom_scalars)\n",
    "\n",
    "#Save weights of best val_accuracy \n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    # Use the model to predict the values from the validation dataset.\n",
    "    test_pred_raw = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = sklearn.metrics.confusion_matrix(test['Cat1'] , test_pred)\n",
    "    \n",
    "    f1_score= sklearn.metrics.f1_score(test['Cat1'], test_pred, average='macro')\n",
    "    accuracy_score=sklearn.metrics.accuracy_score(test['Cat1'], test_pred)\n",
    "    \n",
    "    accu.append(accuracy_score)\n",
    "    f1_score_list.append(f1_score)\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    figure = plot_confusion_matrix(cm,f1_score,accuracy_score, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "        tf.summary.scalar(\"Test accuracy\", accuracy_score, step=epoch)\n",
    "        tf.summary.scalar(\"f1_score\", f1_score, step=epoch)\n",
    "\n",
    "# Define the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlhKv6gmxOOP",
    "outputId": "e317786e-e3a9-4677-89b7-71627c0f3b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 200/2286 [=>............................] - ETA: 3:42 - loss: 1.2137 - accuracy: 0.5336"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d66bc3366786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m history=model.fit(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_Cat1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3318\u001b[0m     \u001b[0mcache_key_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_key_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3319\u001b[0;31m     \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_key_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_cache_key\u001b[0;34m(self, args, kwargs, cache_key_context, include_tensor_ranks_only)\u001b[0m\n\u001b[1;32m   3098\u001b[0m       input_signature = pywrap_tfe.TFE_Py_EncodeArg(inputs,\n\u001b[1;32m   3099\u001b[0m                                                     include_tensor_ranks_only)\n\u001b[0;32m-> 3100\u001b[0;31m       \u001b[0mhashable_input_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_input_signature_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_make_input_signature_hashable\u001b[0;34m(elem)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \"\"\"\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# TODO(slebedev): consider using nest.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__get_cmp_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;34m\"\"\"Returns a hashable eq-comparable key for `self`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;31m# TODO(b/133606651): Decide whether to cache this value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accu=[]\n",
    "f1_score_list=[]\n",
    "### ------- Train the model ------- ###\n",
    "# Batch size table rtx 3080\n",
    "#100T base-uncased: 50\n",
    "#100T large-uncase: 14\n",
    "\n",
    "# Fit the model\n",
    "history=model.fit(\n",
    "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "    y=y_Cat1,\n",
    "    validation_split=0.2,\n",
    "    batch_size=14, #100T base-uncased: 50/ 100T large-uncase: 14\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback, cm_callback,model_checkpoint_callback]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAlV8ode1Btd"
   },
   "outputs": [],
   "source": [
    "# Load the best weights and save the model\n",
    "model.load_weights(checkpoint_filepath)\n",
    "model.save(path_svae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TO-pUAoCoHox"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=path_model_plot,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37287,
     "status": "aborted",
     "timestamp": 1606727674757,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "TLOgxtjpBDAI"
   },
   "outputs": [],
   "source": [
    "### ----- Evaluate the model ------ ###\n",
    "\n",
    "test_pred_raw = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']}, verbose=1) \n",
    "train_pred_raw = model.predict(x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']}, verbose=1) \n",
    "\n",
    "test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "# Calculate the confusion matrix.\n",
    "cm = sklearn.metrics.confusion_matrix(test['Cat1'] , test_pred)\n",
    "cm[np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2) < 0.05] = 0\n",
    "\n",
    "f1_score= sklearn.metrics.f1_score(test['Cat1'], test_pred, average='macro')\n",
    "accuracy_score=sklearn.metrics.accuracy_score(test['Cat1'], test_pred)\n",
    "# Log the confusion matrix as an image summary.\n",
    "figure = plot_confusion_matrix(cm,f1_score,accuracy_score, class_names=class_names)\n",
    "\n",
    "figure.savefig(path_confusion_mat)\n",
    "plt.show() #plt.close(figure)\n",
    "print(\"F1 macro score\", f1_score)\n",
    "print(\"accuracy score\", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35939,
     "status": "aborted",
     "timestamp": 1606727674771,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "K1R5gLG87zA6"
   },
   "outputs": [],
   "source": [
    "report=sklearn.metrics.classification_report(test['Cat1'], test_pred, target_names=class_names, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35332,
     "status": "aborted",
     "timestamp": 1606727674772,
     "user": {
      "displayName": "Lautaro Hickmann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhpnpfV3pwDVltQ1fZd8o2fQLvlZ5wvu2O3-HNK3A=s64",
      "userId": "10165993610530082708"
     },
     "user_tz": -60
    },
    "id": "G7NjT0RWBDk7"
   },
   "outputs": [],
   "source": [
    "#Save data for hierarchical runs\n",
    "np.savez(path_saved_data, test_pred_raw=test_pred_raw, f1_score=f1_score, accuracy_score=accuracy_score,train_pred_raw=train_pred_raw, report=report, accu_list=np.array(accu), f1_score_list=np.array(f1_score_list), history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lh/miniconda3/envs/AMDML/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "512T_10e_Classifier_lvl1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
