{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.4.0-rc4\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# -------- Load libraries ------- ###\n",
    "# Load Huggingface transformers\n",
    "from transformers import TFBertModel, BertConfig, BertTokenizerFast\n",
    "\n",
    "# Then what you need from tensorflow.keras\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# And pandas for data import + sklearn because you always need sklearn\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import itertools\n",
    "import io\n",
    "import os\n",
    "import yaml\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_label(data, test, arguments):\n",
    "    if arguments['labels'] is None:\n",
    "        return data, test    \n",
    "    for arg in arguments['labels']:\n",
    "        if arg[0]=='Target':\n",
    "            for cat in arg[1:][::-1]:\n",
    "                data['Text']=data[cat].str.cat(data['Text'],sep=\". \")\n",
    "                test['Text']=test[cat].str.cat(test['Text'],sep=\". \")\n",
    "        else:\n",
    "            for cat in arg[::-1]:\n",
    "                file=np.load('saved_data/bert-base-uncased/lvl1/100T_5e/Run1/test_pred_raw.npz', allow_pickle=True)\n",
    "                labels=file['train_class_names'][file['train_pred_raw'].argmax(axis=1)]\n",
    "                labels_test=file['test_class_names'][file['test_pred_raw'].argmax(axis=1)]\n",
    "                \n",
    "                data['aux']=labels\n",
    "                data['Text']=data['aux'].str.cat(data['Text'],sep=\". \")\n",
    "                \n",
    "                test['aux']=labels_test\n",
    "                test['Text']=test['aux'].str.cat(test['Text'],sep=\". \")\n",
    "                \n",
    "    return data, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(arguments):\n",
    "    lvl=arguments['lvl']\n",
    "    data_path=arguments['data_path']\n",
    "\n",
    "    # Import data from csv\n",
    "    data = pd.read_csv(data_path + \"/train.csv\")\n",
    "    test = pd.read_csv(data_path + \"/test.csv\")\n",
    "    \n",
    "    # Add labels to text\n",
    "    data, test =append_label(data, test, arguments)\n",
    "\n",
    "    # Select target columns\n",
    "    cat_num = str('Cat' + str(lvl))\n",
    "    \n",
    "    # TODO add fusion text and label for lvl2 & lvl3\n",
    "    data = data[['Text', cat_num]]\n",
    "    test = test[['Text', cat_num]]\n",
    "    \n",
    "    # Training data\n",
    "    # Set model output as categorical and save in new label col\n",
    "    cat_label = str(cat_num + '_label')\n",
    "    data[cat_label] = pd.Categorical(data[cat_num])\n",
    "    # Transform your output to numeric\n",
    "    data[cat_num] = data[cat_label].cat.codes\n",
    "\n",
    "    # Setup test data for logging\n",
    "    # Set model output as categorical and save in new label col\n",
    "    test[cat_label] = pd.Categorical(test[cat_num])\n",
    "    # Transform your output to numeric\n",
    "    test[cat_num] = test[cat_label].cat.codes\n",
    "\n",
    "    \n",
    "    train_class_names = np.unique(data[cat_label])\n",
    "    \n",
    "    test_class_names = np.unique(test[cat_label])\n",
    "    print(\"Class names: \\n Train: {} \\n Test {}\".format(train_class_names, test_class_names))\n",
    "\n",
    "    \n",
    "    train_target = to_categorical(data[cat_num])\n",
    "    test_target=test[cat_num]\n",
    "    \n",
    "    return data, test, train_class_names, test_class_names, train_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, f1_score, accuracy_score, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    Args:\n",
    "        :param cm: (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "        :param class_names: (array, shape = [n]): String names of the integer classes\n",
    "        :param accuracy_score: accuracy score for plotting\n",
    "        :param f1_score: f1_score score for plotting\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix, accuracy {:.4f} \\n f1 Score {:.4f}\".format(accuracy_score, f1_score))\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Compute the labels from the normalized confusion matrix.\n",
    "    labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure\n",
    "\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_bert_model(model_name, config, data, max_length):\n",
    "    # Load the Transformers BERT model\n",
    "    transformer_model = TFBertModel.from_pretrained(model_name, config=config)\n",
    "\n",
    "    # ------- Build the model ------- ###\n",
    "\n",
    "    # TF Keras documentation: https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "\n",
    "    # Load the MainLayer\n",
    "    bert = transformer_model.layers[0]\n",
    "\n",
    "    # Build your model input\n",
    "    input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
    "    attention_mask = Input(shape=(max_length,), name='attention_mask',\n",
    "                           dtype='int32')  # Ignores padded part of sentences\n",
    "    inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "    # Load the Transformers BERT model as a layer in a Keras model\n",
    "    bert_model = bert(inputs)[1]\n",
    "    dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "    pooled_output = dropout(bert_model, training=False)\n",
    "\n",
    "    # Then build your model output\n",
    "    output = Dense(units=len(data.Cat1_label.value_counts()),\n",
    "                   kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='Cat1')(pooled_output)\n",
    "\n",
    "    # And combine it all in a model object\n",
    "    model = Model(inputs=inputs, outputs=output, name='BERT_MultiClass')\n",
    "\n",
    "    # Take a look at the model\n",
    "    print(model.summary())\n",
    "\n",
    "    # ------- Setup training ------- ###\n",
    "\n",
    "    # Set an optimizer\n",
    "    optimizer = Adam(\n",
    "        learning_rate=5e-05,\n",
    "        epsilon=1e-08,\n",
    "        decay=0.01,\n",
    "        clipnorm=1.0)\n",
    "\n",
    "    # Set loss and metrics\n",
    "    loss = CategoricalCrossentropy(from_logits=True)\n",
    "    metric = CategoricalAccuracy('accuracy')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metric)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_tokenized(model_name, config, data, max_length):\n",
    "    # Load BERT tokenizer\n",
    "    \n",
    "    #Load BERT tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path=model_name, config=config)\n",
    "\n",
    "    \n",
    "    #Tokenize the input (takes some time) for training and test (for logging) data\n",
    "    \n",
    "    x = tokenizer(\n",
    "        text=data['Text'].to_list(),\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors='tf',\n",
    "        return_token_type_ids=False,\n",
    "        return_attention_mask=True,\n",
    "        verbose=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(arguments):\n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        \n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw_conf = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
    "        test_pred = np.argmax(test_pred_raw_conf, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(test_target, test_pred)\n",
    "\n",
    "        f1_score = sklearn.metrics.f1_score(test_target, test_pred, average='macro')\n",
    "        accuracy_score = sklearn.metrics.accuracy_score(test_target, test_pred)\n",
    "\n",
    "         # Save weights of best val_accuracy\n",
    "        # TODO Remove and add checkpoint in confusion mat login\n",
    "        \n",
    "        if f1_score_list.max() < f1_score:\n",
    "            model.save_weights(filepath=checkpoint_filepath)\n",
    "            print(\"F1 macro score improved from {.4f} to {.4f}. Model saved\".format(f1_score_list.max(), f1_score))\n",
    "\n",
    "                \n",
    "        accu.append(accuracy_score)\n",
    "        f1_score_list.append(f1_score)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, f1_score, accuracy_score, class_names=test_class_names)\n",
    "        cm_image = plot_to_image(figure)\n",
    "        \n",
    "        \n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "            tf.summary.scalar(\"Test accuracy\", accuracy_score, step=epoch)\n",
    "            tf.summary.scalar(\"f1_score\", f1_score, step=epoch)\n",
    "\n",
    "    print(\"#\" * 150)\n",
    "    print(\"#\" * 150)\n",
    "\n",
    "    # --------- Setup BERT ----------\n",
    "    # Name of the BERT model to use\n",
    "    model_name = arguments['model_name']\n",
    "    # Max length of tokens\n",
    "    max_length = arguments['max_length']\n",
    "    epochs = arguments['epochs']\n",
    "    batch_size = arguments['batch_size']\n",
    "    lvl = arguments['lvl']\n",
    "    \n",
    "    # --------- Setup logs paths ----------\n",
    "    path = \"/\" + model_name + \"/lvl\" + lvl + \"/\" + str(max_length) + \"T_\" + str(epochs) + \"e/\"\n",
    "\n",
    "    aux_path = os.getcwd() + \"/saved_models\" + path\n",
    "    try:\n",
    "        os.makedirs(aux_path)\n",
    "    except OSError:\n",
    "        print(\"%s already exists\" % aux_path)\n",
    "    else:\n",
    "        print(\"Successfully created the directory %s \" % aux_path)\n",
    "    aux_path = os.getcwd() + \"/saved_data\" + path\n",
    "    try:\n",
    "        os.makedirs(aux_path)\n",
    "    except OSError:\n",
    "        print(\"%s already exists\" % aux_path)\n",
    "    else:\n",
    "        print(\"Successfully created the directory %s \" % aux_path)\n",
    "\n",
    "    dir_list = os.listdir(\"./saved_models\" + path)\n",
    "    if len(dir_list) == 0:\n",
    "        run = 1\n",
    "    else:\n",
    "        aux = [int(x[3:]) for x in dir_list]\n",
    "        aux.sort()\n",
    "        run = aux[-1] + 1\n",
    "    path += \"Run\" + str(run)\n",
    "\n",
    "    print(\"Run started: \" + path)\n",
    "\n",
    "    path_model = \"./saved_models\" + path\n",
    "    logdir = path_model + \"/logs\"\n",
    "    path_save_model = path_model + \"/model/\"\n",
    "    checkpoint_filepath = path_model + '/checkpoint/'\n",
    "    log_dir_custom_scalars = logdir + '/custom_metrics'\n",
    "    path_data = \"./saved_data\" + path\n",
    "\n",
    "    try:\n",
    "        os.makedirs(path_data)\n",
    "    except OSError:\n",
    "        print(\"%s already exists\" % aux_path)\n",
    "    else:\n",
    "        print(\"Successfully created the directory %s \" % aux_path)\n",
    "\n",
    "    path_model_plot = path_data + \"/model.png\"\n",
    "    path_confusion_mat = path_data + '/conf.png'\n",
    "    path_saved_data = path_data + \"/test_pred_raw.npz\"\n",
    "\n",
    "    print(\"Config: \" + path + \"\\nRelative paths \" +\n",
    "          \"\\n \\n##### Model data #####\" +\n",
    "          \"\\n \\nlog dir:\" + logdir +\n",
    "          \"\\n \\nlog custom scalars dir:\" + log_dir_custom_scalars +\n",
    "          \"\\n \\nCheckpoint dir:\" + checkpoint_filepath +\n",
    "          \"\\n \\nSaved model dir:\" + path_save_model +\n",
    "          \"\\n \\n \\n##### Plots and predictions #####\" +\n",
    "          \"\\n \\nPlots dir:\" + path_model_plot +\n",
    "          \"\\n \\nConfusion matrix dir:\" + path_confusion_mat +\n",
    "          \"\\n \\nSaved data dir:\" + path_saved_data)\n",
    "\n",
    "    ### --------- Import data --------- ###\n",
    "\n",
    "    data, test, train_class_names, class_names, target = get_data(arguments['data_path'], lvl, arguments)\n",
    "    \n",
    "    ### --------- Load BERT ---------- ###\n",
    "\n",
    "    # Load transformers config and set output_hidden_states to False\n",
    "    config = BertConfig.from_pretrained(model_name)\n",
    "    config.output_hidden_states = False\n",
    "\n",
    "    \n",
    "    # Load the Transformers BERT model\n",
    "    \n",
    "    model = get_bert_model(model_name, config, data, max_length)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Tokenize the input (takes some time) for training and test (for logging) data\n",
    "\n",
    "    x = get_tokenized(model_name, config, data, max_length)\n",
    "    \n",
    "    test_x = get_tokenized(model_name, config, test, max_length)\n",
    "\n",
    "    ### ------- Callbacks ------- ###\n",
    "    # Tensorboard callback\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1, write_graph=False,\n",
    "                                                          write_images=True, profile_batch='2,9')\n",
    "    # Custom summary writer for custom scalars and confusion matrix\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir_custom_scalars)\n",
    "\n",
    "    \n",
    "\n",
    "    # Define the per-epoch callback.\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "    accu = []\n",
    "    f1_score_list = []\n",
    "    ### ------- Train the model ------- ###\n",
    "    # Batch size table rtx 3080\n",
    "    # 100T base-uncased: 50\n",
    "    # 100T large-uncased: 14\n",
    "\n",
    "    # Fit the model\n",
    "    history = model.fit(\n",
    "        x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "        y=target,  # y_Cat1,\n",
    "        validation_split=0.2,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[tensorboard_callback, cm_callback, model_checkpoint_callback])\n",
    "\n",
    "    # Load the best weights and save the model\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    model.save(path_save_model)\n",
    "\n",
    "    tf.keras.utils.plot_model(\n",
    "        model,\n",
    "        to_file=path_model_plot,\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        rankdir=\"TB\",\n",
    "        expand_nested=False,\n",
    "        dpi=96,\n",
    "    )\n",
    "\n",
    "    # ----- Evaluate the model ------   \n",
    "\n",
    "    test_pred_raw = model.predict(x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']},\n",
    "                                  verbose=1)\n",
    "    train_pred_raw = model.predict(x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']}, verbose=1)\n",
    "\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = sklearn.metrics.confusion_matrix(test_target, test_pred)\n",
    "    cm[np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2) < 0.05] = 0\n",
    "\n",
    "    f1_score = sklearn.metrics.f1_score(test_target, test_pred, average='macro')\n",
    "    accuracy_score = sklearn.metrics.accuracy_score(test_target, test_pred)\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    figure = plot_confusion_matrix(cm, f1_score, accuracy_score, class_names=class_names)\n",
    "\n",
    "    figure.savefig(path_confusion_mat)\n",
    "    plt.close(figure)\n",
    "\n",
    "    # noinspection PyTypeChecker\n",
    "    report = sklearn.metrics.classification_report(test_target, test_pred, target_names=class_names, digits=4)\n",
    "    accu = np.array(accu)\n",
    "    f1_score_list = np.array(f1_score_list)\n",
    "\n",
    "    # Save data for hierarchical runs\n",
    "    np.savez(path_saved_data, test_pred_raw=test_pred_raw, f1_score=f1_score, accuracy_score=accuracy_score,\n",
    "             train_pred_raw=train_pred_raw, report=report, accu_list=accu, f1_score_list=f1_score_list,\n",
    "             hist=history.history, train_class_names=train_class_names,test_class_names=test_class_names)\n",
    "\n",
    "    print(\"Run finished: \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    list_args = sys.argv[1:]\n",
    "\n",
    "    print(\"Tensorflow version: \", tf.__version__)\n",
    "\n",
    "    # rtx 3080 tf 2.4.0-rc4 bug\n",
    "    gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "    if len(list_args) < 1:\n",
    "        print(\"Config missing\")\n",
    "        sys.exit(2)\n",
    "\n",
    "    for conf in list_args:\n",
    "        with open(conf) as f:\n",
    "            arguments = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        for i in range(arguments['repetitions']):\n",
    "            run_experiment(arguments)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
